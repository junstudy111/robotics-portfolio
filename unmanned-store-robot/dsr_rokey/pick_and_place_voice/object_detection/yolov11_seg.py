# object_detection/yolov11_seg.py (ì˜¬ë°”ë¥¸ ë²„ì „)
# v4 ìë™ê²€ì¶œ

import os
import json
import time
import cv2
import numpy as np
import rclpy
from ament_index_python.packages import get_package_share_directory
from ultralytics import YOLO

# âŒ ì´ ì¤„ ì‚­ì œ! (í˜¹ì‹œ ìˆìœ¼ë©´)
# from object_detection.yolov11_seg import YoloModel

PACKAGE_NAME = "pick_and_place_voice"
PACKAGE_PATH = get_package_share_directory(PACKAGE_NAME)

YOLO_MODEL_FILENAME = "yolov11_seg_best.pt"  
YOLO_CLASS_NAME_JSON = "class_name_tool.json"

YOLO_MODEL_PATH = os.path.join(PACKAGE_PATH, "resource", YOLO_MODEL_FILENAME)
YOLO_JSON_PATH = os.path.join(PACKAGE_PATH, "resource", YOLO_CLASS_NAME_JSON)


class YoloModel:
    def __init__(self):
        print(f"[YoloModel] Loading Segmentation Model from: {YOLO_MODEL_PATH}")
        
        if not os.path.exists(YOLO_MODEL_PATH):
            print(f"âŒ Error: Model file not found at {YOLO_MODEL_PATH}")
            print("   Please copy your 'best.pt' to the resource folder.")
        
        self.model = YOLO(YOLO_MODEL_PATH)
        
        print(f"[YoloModel] Loading Class Map from: {YOLO_JSON_PATH}")
        with open(YOLO_JSON_PATH, "r", encoding="utf-8") as file:
            class_dict = json.load(file)
            self.class_map = {k.lower(): v for k, v in class_dict.items()}
            
        print(f"âœ… Class Map Loaded: {self.class_map}")

    def get_frames(self, img_node, duration=1.0):
        """ì§€ì •ëœ ì‹œê°„ ë™ì•ˆ í”„ë ˆì„ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
        end_time = time.time() + duration
        frames = []

        while time.time() < end_time:
            rclpy.spin_once(img_node)
            frame = img_node.get_color_frame()
            if frame is not None:
                frames.append(frame)
            time.sleep(0.01)

        return frames

    def get_best_detection(self, img_node, target):
        """
        íƒ€ê²Ÿ(target) ì´ë¦„ì— í•´ë‹¹í•˜ëŠ” ë¬¼ì²´ë¥¼ ì°¾ì•„ì„œ
        Box, Angle, Scoreë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)
        """
        box, angle, score, mask = self.get_best_detection_with_mask(img_node, target)
        return box, angle, score

    def get_best_detection_with_mask(self, img_node, target):
        """
        íƒ€ê²Ÿ(target) ì´ë¦„ì— í•´ë‹¹í•˜ëŠ” ë¬¼ì²´ë¥¼ ì°¾ì•„ì„œ
        Box, Angle, Score, Maskë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        frames = self.get_frames(img_node)
        if not frames:
            print("âš ï¸ No frames captured from camera.")
            return None, 0.0, None, None

        # 1. Segmentation ëª¨ë“œë¡œ ì¶”ë¡  (conf=0.5 ì´ìƒë§Œ ê°ì§€)
        results = self.model(frames, conf=0.5, verbose=False)
        
        # 2. íƒ€ê²Ÿ ì´ë¦„(target)ì„ IDë¡œ ë³€í™˜ (ì†Œë¬¸ì ì²˜ë¦¬)
        target_lower = target.lower()
        
        if target_lower in self.class_map:
            target_id = self.class_map[target_lower]
            print(f"ğŸ” Searching for '{target}' (ID: {target_id})...")
        else:
            print(f"âš ï¸ Target '{target}' not found in JSON. Available keys: {list(self.class_map.keys())}")
            return None, 0.0, None, None

        best_det = None
        max_score = -1.0
        
        # 3. ê²°ê³¼ ë¶„ì„: íƒ€ê²Ÿ IDì™€ ì¼ì¹˜í•˜ëŠ” ê²ƒ ì¤‘ ê°€ì¥ ì ìˆ˜ ë†’ì€ ê²ƒ ì°¾ê¸°
        for res in results:
            if res.boxes is None or res.masks is None:
                continue
                
            # box, mask, cls(í´ë˜ìŠ¤ID), score(í™•ë¥ )ë¥¼ ë¬¶ì–´ì„œ ë°˜ë³µ
            for box, mask, cls, score in zip(res.boxes, res.masks, res.boxes.cls, res.boxes.conf):
                current_id = int(cls)
                current_score = float(score)

                if current_id == target_id:
                    if current_score > max_score:
                        max_score = current_score
                        best_det = {
                            "box": box.xyxy[0].cpu().numpy(), # [x1, y1, x2, y2]
                            "mask": mask.xy[0],               # ìœ¤ê³½ì„  ì¢Œí‘œ
                            "score": current_score
                        }

        if best_det is None:
            print(f"âŒ Failed to detect object ID {target_id} in current frame.")
            return None, 0.0, None, None

        # 4. ê°ë„ ê³„ì‚° (Segmentation ìœ¤ê³½ì„  í™œìš©)
        angle = self._calculate_angle_from_mask(best_det["mask"])
        
        print(f"âœ… Detect Success! Score: {max_score:.2f}, Angle: {angle:.1f}Â°")
        
        # maskë„ í•¨ê»˜ ë°˜í™˜
        return best_det["box"], angle, best_det["score"], best_det["mask"]

    def _calculate_angle_from_mask(self, mask_contour):
        """ë§ˆìŠ¤í¬ ìœ¤ê³½ì„ ì„ ì´ìš©í•´ íšŒì „ ê°ë„(Angle) ê³„ì‚°"""
        cnt = np.array(mask_contour, dtype=np.int32)
        if len(cnt) == 0: 
            return 0.0

        # ìµœì†Œ ë©´ì  ì‚¬ê°í˜• (Rotated Rectangle) êµ¬í•˜ê¸°
        rect = cv2.minAreaRect(cnt)
        (cx, cy), (rw, rh), angle = rect

        # ë¡œë´‡ ê·¸ë¦¬í¼ê°€ ì§§ì€ ë©´ì„ ì¡ë„ë¡ ê°ë„ ë³´ì •
        if rw < rh:
            target_angle = angle
        else:
            target_angle = angle + 90

        # ê°ë„ ì •ê·œí™” (-90ë„ ~ 90ë„ ì‚¬ì´ë¡œ ë§ì¶¤)
        while target_angle > 90: 
            target_angle -= 180.0
        while target_angle < -90: 
            target_angle += 180.0

        return target_angle